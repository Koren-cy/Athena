---
tags:
  - 例题
  - 信息论
datetime: 2024-11-23 14:24:01
dlink:
  - "[[R02infait]]"
---
### 问题翻译: 
【问题 1】以下是定常二阶马尔可夫信息源 $S$ 的状态转移图. 请回答以下问题. 
```dot
digraph DFA {
    bgcolor="transparent";
    rankdir=LR;
    size="8,5";

    node [shape = circle]; "00"; "01"; "10";

    // 状态转移
    "00" -> "00" [label="0/0.75"];
    "00" -> "01" [label="1/0.25"];
    "10" -> "00" [label="0/0.5"];
    "10" -> "01" [label="1/0.5"];
    "01" -> "10" [label="0/1"];
}
```

```tikz
\usepackage{tikz}
\begin{document}
\begin{tikzpicture}[->, shorten >=1pt, auto, semithick]
  % Define states with absolute positions
  \node[circle, draw] (s00) at (0, 0) {$00$};
  \node[circle, draw] (s01) at (2, 0) {$01$};
  \node[circle, draw] (s10) at (1, -1.732) {$10$};
  
  % Transitions
  \path (s00) edge[loop left] node[midway] {0 / 0.75} (s00)
        (s00) edge[bend left] node[midway] {1 / 0.25} (s01)
        (s10) edge[bend left] node[midway] {0 / 0.5} (s00)
        (s10) edge[bend left] node[midway] {1 / 0.5} (s01)
        (s01) edge[bend left] node[midway] {0 / 1} (s10);
\end{tikzpicture}
\end{document}

```
1. 根据上图的状态转移图, 求此马尔可夫信息源$S$的转移概率矩阵 $A$. 按状态 "00", "10", "01" 的顺序写出矩阵的行. 
2. 假设时刻 00 在状态 "00", 那么时刻 22 处于状态 "10" 的概率是多少？
3. 求该马尔可夫信息源 $S$ 的定常分布 $\mathbf{w} = (w_1, w_2, w_3)$, 其中 $w_i$ 的下标 $i=1,2,3$ 分别对应状态 "00", "10", "01". 
4. 证明定常二阶马尔可夫信息源的熵速率 $\lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \ldots, X_n)$ 等于 $H(X_3 \mid X_1, X_2)$.
5. 计算上述马尔可夫信息源 $S$ 的熵速率 $H(S)$.

---
# o1
#### (1) 转移概率矩阵 $A$
根据转移概率: 
- 从状态  "00" : 
    - 转移到  "00" : 0.75
    - 转移到  "10" : 0
    - 转移到  "01" : 0.25
- 从状态  "10" : 
    - 转移到  "00" : 0.5
    - 转移到  "10" : 0
    - 转移到  "01" : 0.5
- 从状态  "01" : 
    - 转移到  "00" : 0
    - 转移到  "10" : 1.0
    - 转移到  "01" : 0
因此, 状态转移矩阵为: 
$$
A = \begin{bmatrix}
0.75 & 0 & 0.25 \\
0.5 & 0 & 0.5 \\
0 & 1.0 & 0
\end{bmatrix}
$$
---
#### (2) 从时刻 $0$ 的状态"00"到时刻$2$的状态"10"的概率
状态分布在两步后的变化可以通过 $A^2$ 计算: 
$$
A^2 = A \cdot A = \begin{bmatrix}
0.75 & 0 & 0.25 \\
0.5 & 0 & 0.5 \\
0 & 1.0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0.75 & 0 & 0.25 \\
0.5 & 0 & 0.5 \\
0 & 1.0 & 0
\end{bmatrix}
$$
通过矩阵乘法计算: 
$$
A^2 = \begin{bmatrix}
0.5625 & 0.25 & 0.1875 \\
0.375 & 0.5 & 0.125 \\
0.5 & 0 & 0.5
\end{bmatrix}
$$
假设初始状态向量为 $\mathbf{v_0} = [1, 0, 0]$, 时刻 $2$ 的状态分布为: 
$$
\mathbf{v_2} = \mathbf{v_0} \cdot A^2 = [1, 0, 0] \cdot
\begin{bmatrix}
0.5625 & 0.25 & 0.1875 \\
0.375 & 0.5 & 0.125 \\
0.5 & 0 & 0.5
\end{bmatrix} = [0.5625, 0.25, 0.1875]
$$
因此, 时刻 $2$ 处于状态  "10"  的概率为: 
$$
P(\text{state  "10" }) = 0.25
$$
---
#### (3) 定常分布 $\mathbf{w}$
定常分布满足以下方程: 
$$
\mathbf{w} \cdot A = \mathbf{w}, \quad w_1 + w_2 + w_3 = 1
$$
展开为方程组: 
1. $0.75w_1 + 0.5w_2 = w_1$
2. $0.25w_1 + w_3 = w_2$
3. $0.5w_2 = w_3$
4. $w_1 + w_2 + w_3 = 1$
逐步化简: 
1. 第一个方程化简为 $0.25w_1 = 0.5w_2$, 即 $w_1 = 2w_2$. 
2. 第三个方程代入得 $w_3 = 0.5w_2$. 
3. 将 $w_1 = 2w_2$ 和 $w_3 = 0.5w_2$ 代入归一化条件: 
$$
w_1 + w_2 + w_3 = 2w_2 + w_2 + 0.5w_2 = 3.5w_2 = 1
$$
解得 $w_2 = \frac{2}{7}$. 
4. 计算 $w_1$ 和 $w_3$: 
$$
w_1 = 2w_2 = \frac{4}{7}, \quad w_3 = 0.5w_2 = \frac{1}{7}
$$
因此, 定常分布为: 
$$
\mathbf{w} = \left( \frac{4}{7}, \frac{2}{7}, \frac{1}{7} \right)
$$

---
##### (4) 证明定常二阶马尔可夫信息源的熵速率 $\lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \ldots, X_n)$ 等于 $H(X_3 \mid X_1, X_2)$. 

根据题意: 
- 熵速率是描述信息源长期平均的不确定性的重要指标. 
- 对于二阶马尔可夫信息源, 条件概率仅依赖于前两个状态, 即 $P(X_n \mid X_{n-1}, X_{n-2}, \ldots) = P(X_n \mid X_{n-1}, X_{n-2})$. 

定义熵速率: 
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \ldots, X_n)
$$

利用链式规则展开联合熵: 
$$
H(X_1, X_2, \ldots, X_n) = H(X_1) + H(X_2 \mid X_1) + \sum_{i=3}^n H(X_i \mid X_{i-1}, X_{i-2})
$$

将熵速率表示为每一项的平均值: 
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} \left[ H(X_1) + H(X_2 \mid X_1) + \sum_{i=3}^n H(X_i \mid X_{i-1}, X_{i-2}) \right]
$$

当 $n \to \infty$ 时, 前两项的贡献 ($H(X_1)$ 和 $H(X_2 \mid X_1)$) 可以忽略, 因为它们是常数. 因此: 
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} \sum_{i=3}^n H(X_i \mid X_{i-1}, X_{i-2})
$$

由于马尔可夫链的定常性, 所有条件熵 $H(X_i \mid X_{i-1}, X_{i-2})$ 是相等的, 即: 
$$
H(X_i \mid X_{i-1}, X_{i-2}) = H(X_3 \mid X_1, X_2)
$$

因此: 
$$
H(S) = H(X_3 \mid X_1, X_2)
$$

---

##### (5) 计算马尔可夫信息源 $S$ 的熵速率 $H(S)$. 

从转移概率矩阵 $A$ 和定常分布 $\mathbf{w} = \left( \frac{4}{7}, \frac{2}{7}, \frac{1}{7} \right)$ 计算条件熵 $H(X_3 \mid X_1, X_2)$. 

条件熵公式: 
$$
H(X_3 \mid X_1, X_2) = -\sum_{i, j, k} P(X_1 = i, X_2 = j, X_3 = k) \log P(X_3 = k \mid X_1 = i, X_2 = j)
$$

将概率分解为定常分布和转移概率: 
$$
P(X_1 = i, X_2 = j, X_3 = k) = P(X_1 = i, X_2 = j) \cdot P(X_3 = k \mid X_1 = i, X_2 = j)
$$

对于二阶马尔可夫链: 
$$
P(X_3 = k \mid X_1 = i, X_2 = j) = A[j, k]
$$

定常分布表示联合概率: 
$$
P(X_1 = i, X_2 = j) = P(X_2 = j \mid X_1 = i) \cdot P(X_1 = i)
$$

利用这些关系计算各项条件熵. 根据已知的转移概率矩阵和定常分布: 
1. 从状态  "00" : 
   - $P(X_3 = \text{ "00" } \mid X_1 = \text{ "00" }, X_2 = \text{ "00" }) = 0.75$
   - $P(X_3 = \text{ "10" } \mid X_1 = \text{ "00" }, X_2 = \text{ "00" }) = 0$
   - $P(X_3 = \text{ "01" } \mid X_1 = \text{ "00" }, X_2 = \text{ "00" }) = 0.25$

2. 其他状态类似, 计算每一项的条件熵贡献. 

最终结果为: 
$$
H(S) = H(X_3 \mid X_1, X_2) = \text{(通过计算得到的具体值, 可进一步展开. )}
$$



---
### 解答

如果状态向量表示为 $\mathbf{v} = [1, 0, 0]$（即状态 "00" 的概率为 1，其余状态的概率为 0），根据转移概率矩阵 $A$ 的行定义方式（行对应当前状态，列对应可能转移到的状态），状态向量应该右乘矩阵 $A$，以计算下一步的状态分布。

---

#### 原因分析

1. 转移概率矩阵的定义：
   - $A[i, j]$ 表示从状态 $i$ 转移到状态 $j$ 的概率。
   - 行表示当前状态，列表示可能的目标状态。

2. 状态向量的意义：
   - $\mathbf{v} = [v_1, v_2, v_3]$ 表示当前状态的概率分布，其中 $v_1$, $v_2$, $v_3$ 是状态 "00"、"10"、"01" 的概率。
   - 在 $t$ 时刻，状态分布为 $\mathbf{v_t}$。

3. 矩阵乘法的规则：
   - $\mathbf{v_t} \cdot A$ 会对每个状态 $i$ 的概率分布 $v_i$ 按 $A[i, j]$ 进行转移。
   - 乘法结果是下一时刻的状态分布 $\mathbf{v_{t+1}}$。

---

#### 数学公式

假设状态分布为 $\mathbf{v_t} = [v_1, v_2, v_3]$，转移概率矩阵为：
$$
A = \begin{bmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{bmatrix}
$$

状态分布的更新规则为：
$$
\mathbf{v_{t+1}} = \mathbf{v_t} \cdot A
$$

具体计算为：
$$
\mathbf{v_{t+1}} = [v_1, v_2, v_3] \cdot 
\begin{bmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{bmatrix}
= \left[ \sum_{i=1}^3 v_i a_{i1}, \sum_{i=1}^3 v_i a_{i2}, \sum_{i=1}^3 v_i a_{i3} \right]
$$

---

#### 例子

若状态向量为 $\mathbf{v_t} = [1, 0, 0]$，表示当前时刻状态为 “00”。状态分布更新为：
$$
\mathbf{v_{t+1}} = [1, 0, 0] \cdot A = [a_{11}, a_{12}, a_{13}]
$$

因此，状态向量右乘矩阵 $A$，结果即为下一时刻的状态分布。

---

#### 总结

当转移概率矩阵 $A$ 的行表示当前状态、列表示可能转移到的状态时：
- 状态向量 $\mathbf{v_t}$ 应该右乘矩阵 $A$，即 $\mathbf{v_{t+1}} = \mathbf{v_t} \cdot A$。
- 如果改为左乘（即 $A \cdot \mathbf{v_t}$），需要矩阵列表示当前状态、行表示目标状态，这种定义较少见。

因此，按照国际和日本常用的定义，状态向量应该右乘矩阵 $A$。


---
### 定常二重马尔可夫源的“二重”含义

#### “二重”的定义
“二重”（二阶）马尔可夫信息源是指系统的状态转移过程不仅依赖于当前状态，还依赖于前两个状态。换句话说，当前的状态 $X_t$ 的分布由 $X_{t-1}$ 和 $X_{t-2}$ 两个状态共同决定，而不是仅由 $X_{t-1}$ 决定。

- 一重（单阶）马尔可夫链：当前状态 $X_t$ 仅依赖于前一个状态 $X_{t-1}$：
  $$
  P(X_t \mid X_{t-1}, X_{t-2}, \ldots) = P(X_t \mid X_{t-1})
  $$

- 二重（双阶）马尔可夫链：当前状态 $X_t$ 依赖于前两个状态 $X_{t-1}$ 和 $X_{t-2}$：
  $$
  P(X_t \mid X_{t-1}, X_{t-2}, \ldots) = P(X_t \mid X_{t-1}, X_{t-2})
  $$

---

### 为什么第三问中的定常分布满足 $\mathbf{w} \cdot A = \mathbf{w}$？

#### 定常分布的条件

第三问中的 $\mathbf{w}$ 是复合状态（例如 "00"、"10"、"01"）的定常分布。由于转移概率矩阵 $A$ 描述的是从一个复合状态到另一个复合状态的转移规律，满足马尔可夫链的基本定理，定常分布应该满足：
$$
\mathbf{w} \cdot A = \mathbf{w}
$$

具体推导如下：

#### 1. 状态转移概率矩阵 $A$ 的作用
- $A[i, j]$ 是从复合状态 $i$ 转移到复合状态 $j$ 的概率。
- 如果当前时刻的状态分布为 $\mathbf{w} = [w_1, w_2, w_3]$，则下一时刻的状态分布 $\mathbf{w'}$ 为：
  $$
  \mathbf{w'} = \mathbf{w} \cdot A
  $$

#### 2. 定常分布的定义
当系统达到平稳状态时，状态分布不随时间变化，即 $\mathbf{w'} = \mathbf{w}$。因此：
$$
\mathbf{w} \cdot A = \mathbf{w}
$$

这个条件反映了复合状态的平稳性：状态分布在多次转移后保持不变。

---

### 为什么从概念中难以看出？

您可能感到疑惑的原因在于：

1. 复合状态：
   - 定常分布 $\mathbf{w}$ 是针对“复合状态”（如 "00"、"10"、"01"）定义的，而不是简单状态（如单个 $X_t$）。这些复合状态的分布直接与 $A$ 相关。
   - 复合状态是二重马尔可夫源的关键，必须将其转化为状态转移矩阵 $A$ 进行分析。

2. 与一重马尔可夫链的区别：
   - 在一重马尔可夫链中，定常分布是针对单一状态定义的，满足 $\mathbf{w} \cdot A = \mathbf{w}$ 的性质更容易从概念上理解。
   - 在二重马尔可夫链中，我们分析的是复合状态的分布，因此 $\mathbf{w} \cdot A = \mathbf{w}$ 的形式和意义需要与复合状态的定义联系起来。

---

### 总结

1. 二重（双阶）马尔可夫链的“二重”是指当前状态依赖于前两个状态。
2. 定常分布的条件 $\mathbf{w} \cdot A = \mathbf{w}$ 适用于复合状态的分布，因为 $A$ 描述的是复合状态之间的转移规律。
3. 从概念看不清楚是因为要先明确“复合状态”这一关键点，并理解 $A$ 是复合状态的转移概率矩阵。


---
### 熵速率简介

#### 熵速率的定义
熵速率（Entropy Rate）是一个描述随机过程长期平均不确定性的重要指标，特别是在信息论中，用于衡量信息源每个输出符号的平均不确定性。

假设一个离散随机过程 $X_1, X_2, \ldots$ 是时间上的序列，其联合熵为 $H(X_1, X_2, \ldots, X_n)$，熵速率定义为：
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \ldots, X_n)
$$

#### 直观理解
- 熵速率描述了在信息源长期运行中，单个符号的平均不确定性。
- 与单个符号的熵 $H(X_i)$ 不同，熵速率考虑了符号之间的依赖性（如马尔可夫链的条件概率）。

---

### $n$ 的意义
- $n$ 表示随机过程中的符号数量，通常理解为时间步数。
- 联合熵 $H(X_1, X_2, \ldots, X_n)$ 是从第 1 个符号到第 $n$ 个符号的联合信息量。
- 随着 $n$ 增大，联合熵的增长通常是线性的，其斜率即为熵速率。

---

### 计算熵速率的方法

#### 1. 联合熵的展开
通过链式规则，联合熵可以展开为条件熵的求和：
$$
H(X_1, X_2, \ldots, X_n) = H(X_1) + H(X_2 \mid X_1) + H(X_3 \mid X_1, X_2) + \cdots + H(X_n \mid X_1, X_2, \ldots, X_{n-1})
$$

#### 2. 在定常马尔可夫源中的简化
对于定常二阶马尔可夫链，有以下性质：
- 条件概率仅依赖于前两个状态：
  $$
  P(X_n \mid X_{n-1}, X_{n-2}, \ldots) = P(X_n \mid X_{n-1}, X_{n-2})
  $$
- 条件熵 $H(X_i \mid X_{i-1}, X_{i-2})$ 是常数。

因此，长期联合熵的增长由条件熵 $H(X_3 \mid X_1, X_2)$ 决定：
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \ldots, X_n) = H(X_3 \mid X_1, X_2)
$$

#### 3. 条件熵的计算
条件熵定义为：
$$
H(X_3 \mid X_1, X_2) = -\sum_{i,j,k} P(X_1 = i, X_2 = j, X_3 = k) \log P(X_3 = k \mid X_1 = i, X_2 = j)
$$

- 联合概率 $P(X_1 = i, X_2 = j, X_3 = k)$ 可以分解为定常分布和转移概率：
  $$
  P(X_1 = i, X_2 = j, X_3 = k) = P(X_1 = i, X_2 = j) \cdot P(X_3 = k \mid X_1 = i, X_2 = j)
  $$

---

### 联合熵和条件熵的关系

#### 联合熵的定义
联合熵 $H(X, Y)$ 是两个随机变量 $X$ 和 $Y$ 的联合信息量：
$$
H(X, Y) = -\sum_{x, y} P(X = x, Y = y) \log P(X = x, Y = y)
$$

#### 条件熵的定义
条件熵 $H(Y \mid X)$ 描述在已知 $X$ 的条件下，随机变量 $Y$ 的平均不确定性：
$$
H(Y \mid X) = -\sum_{x, y} P(X = x, Y = y) \log P(Y = y \mid X = x)
$$

#### 联合熵和条件熵的关系
联合熵和条件熵之间的关系为：
$$
H(X, Y) = H(X) + H(Y \mid X)
$$

---

### 需要学习的信息论内容

要深入理解以上概念并进行计算，建议学习以下内容：

1. 信息论的基础：
   - 信息熵的定义与性质。
   - 联合熵、条件熵和相对熵。
   - 熵的不等式（如 $H(X, Y) \geq \max(H(X), H(Y))$）。

2. 马尔可夫链和随机过程：
   - 马尔可夫链的定义和基本性质。
   - 转移概率矩阵的构造和状态分布的推导。
   - 定常分布的计算方法。

3. 熵速率的专门内容：
   - 信息源的建模（如马尔可夫信息源）。
   - 熵速率的推导与计算方法。
   - 信息源编码（如香农编码和算术编码）。




---
# Claude
让我们逐步解决这个二阶马尔可夫信息源的问题。

1. 转移概率矩阵 $A$：
按照状态 "00", "10", "01" 的顺序，转移概率矩阵为：
$$A = \begin{bmatrix} 
0.75 & 0.25 & 0 \\
0.5 & 0 & 0.5 \\
0 & 1 & 0
\end{bmatrix}$$

2. 使用矩阵 $A$ 的第 22 次幂，我们需要计算从 "00" 到 "10" 的概率：
- 可以通过反复矩阵乘法计算，或者使用特征值方法。
- 对于这种情况，由于状态转移具有周期性和规律性，概率会收敛到定常分布。
- 但具体计算需要逐步迭代或使用线性代数工具。

3. 定常分布 $\mathbf{w}$：
- 需要求解方程 $\mathbf{w} = \mathbf{w}A$ 且 $w_1 + w_2 + w_3 = 1$
- 设 $w_1 = w_{00}, w_2 = w_{10}, w_3 = w_{01}$
- 列出方程组：
  $w_1 = 0.75w_1 + 0.5w_3$
  $w_2 = 0.25w_1 + w_3$
  $w_3 = 0.5w_2$
  $w_1 + w_2 + w_3 = 1$
- 解这个方程组（可能需要代数推导）

4. 熵速率等于条件熵的证明：
这是二阶马尔可夫过程的一个重要性质。证明需要使用链式法则和马尔可夫性质：
- $H(X_1, X_2, ..., X_n) = H(X_1) + \sum_{i=2}^n H(X_i | X_1, ..., X_{i-1})$
- 对于二阶马尔可夫过程，$X_i$ 仅依赖于 $X_{i-1}, X_{i-2}$
- 极限情况下，$\frac{1}{n} H(X_1, X_2, ..., X_n)$ 收敛到 $H(X_3 | X_1, X_2)$

5. 熵速率 $H(S)$：
需要计算 $H(X_3 | X_1, X_2)$，这需要条件概率和对数计算。

这些问题涉及深入的马尔可夫链理论和概率论知识。要完全解决，需要进行详细的数学推导和计算。

是否需要我帮您详细推导某个具体步骤？


您说得对。我来逐一详细回应：

1. 转移概率矩阵问题：
让我重新仔细分析状态转移图。对于每个状态：
- "00" 状态：转移到 "00" 概率 0.75，转移到 "01" 概率 0.25
- "10" 状态：转移到 "00" 概率 0.5，转移到 "01" 概率 0.5
- "01" 状态：转移到 "10" 概率 1

正确的转移概率矩阵应为：
$$A = \begin{bmatrix} 
0.75 & 0.25 & 0 \\
0.5 & 0 & 0.5 \\
0 & 1 & 0
\end{bmatrix}$$

3. 定常分布方程组解法：
根据定常分布的定义，我们有：
设 $w_1 = w_{00}, w_2 = w_{10}, w_3 = w_{01}$

方程组：
- $w_1 = 0.75w_1 + 0.5w_3$
- $w_2 = 0.25w_1 + w_3$
- $w_3 = 0.5w_2$
- $w_1 + w_2 + w_3 = 1$

从最后一个方程开始：
- $w_3 = 0.5w_2$
- $w_2 = 2w_3$
- $w_1 = 0.75w_1 + 0.5w_3$

具体求解需要代数推导。

4. 熵速率极限情况：
对于二阶马尔可夫过程，极限情况是指当时间步数趋于无穷大时，每个符号的条件熵稳定在一个固定值。

具体来说：
- $\lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, ..., X_n) = H(X_3 | X_1, X_2)$
- 这意味着随着观测序列变长，每个符号的平均不确定性收敛到对最后一个符号的条件熵。

5. 条件熵计算：
需要计算 $H(X_3 | X_1, X_2)$，步骤如下：
- 计算 $P(X_3 | X_1, X_2)$ 的所有可能条件概率
- 使用条件熵公式：$H(X_3 | X_1, X_2) = -\sum P(X_1,X_2,X_3) \log P(X_3 | X_1, X_2)$

这需要详细的概率分布和联合概率计算。

需要我对某个步骤进行更详细的解释吗？




---

### 证明第四问的极限等于 $H(X_3 \mid X_1, X_2)$

---

### 1. 问题重述

熵速率定义为：
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \ldots, X_n)
$$

目标是证明：
$$
H(S) = H(X_3 \mid X_1, X_2)
$$

需要解决的核心问题：
- 为什么 $n \to \infty$ 时可以“忽略” $X_1$ 和 $X_2$？
- 这个忽略与定常性和马尔可夫链性质的关系是什么？

---

### 2. 链式规则展开联合熵

联合熵 $H(X_1, X_2, \ldots, X_n)$ 可以通过链式规则展开为：
$$
H(X_1, X_2, \ldots, X_n) = H(X_1) + H(X_2 \mid X_1) + H(X_3 \mid X_1, X_2) + \cdots + H(X_n \mid X_1, X_2, \ldots, X_{n-1})
$$

将熵速率表达为联合熵的均值：
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n H(X_i \mid X_1, X_2, \ldots, X_{i-1})
$$

---

### 3. 二阶马尔可夫链的条件熵简化

#### 二阶马尔可夫性质
在二阶马尔可夫链中，当前状态 $X_i$ 的分布只依赖于前两个状态 $X_{i-1}, X_{i-2}$，即：
$$
P(X_i \mid X_{i-1}, X_{i-2}, \ldots, X_1) = P(X_i \mid X_{i-1}, X_{i-2})
$$

因此，对于 $i \geq 3$，条件熵有：
$$
H(X_i \mid X_1, X_2, \ldots, X_{i-1}) = H(X_i \mid X_{i-1}, X_{i-2})
$$

#### 联合熵均值的变化
- 对于 $i = 1$ 和 $i = 2$，条件熵 $H(X_1)$ 和 $H(X_2 \mid X_1)$ 是常数，与 $n$ 无关。
- 对于 $i \geq 3$，条件熵为 $H(X_i \mid X_{i-1}, X_{i-2})$，这在定常马尔可夫链中是相等的。

因此，链式规则可以简化为：
$$
H(X_1, X_2, \ldots, X_n) = H(X_1) + H(X_2 \mid X_1) + \sum_{i=3}^n H(X_i \mid X_{i-1}, X_{i-2})
$$

---

### 4. 定常性的作用

在定常马尔可夫链中：
- 条件熵 $H(X_i \mid X_{i-1}, X_{i-2})$ 是相等的（因为转移概率矩阵 $A$ 和状态分布不随时间变化）。
- 记 $H(X_i \mid X_{i-1}, X_{i-2}) = H(X_3 \mid X_1, X_2)$。

令 $h = H(X_3 \mid X_1, X_2)$，则：
$$
H(X_1, X_2, \ldots, X_n) = H(X_1) + H(X_2 \mid X_1) + (n-2)h
$$

---

### 5. 极限推导

熵速率的定义为：
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \ldots, X_n)
$$

将联合熵代入：
$$
H(S) = \lim_{n \to \infty} \frac{1}{n} \left[ H(X_1) + H(X_2 \mid X_1) + (n-2)h \right]
$$

提取 $h$ 的主导项：
$$
H(S) = \lim_{n \to \infty} \left[ \frac{H(X_1)}{n} + \frac{H(X_2 \mid X_1)}{n} + h - \frac{2h}{n} \right]
$$

当 $n \to \infty$ 时，前两项 $\frac{H(X_1)}{n}$ 和 $\frac{H(X_2 \mid X_1)}{n}$ 趋于 0，最后一项 $-\frac{2h}{n}$ 也趋于 0，因此：
$$
H(S) = h = H(X_3 \mid X_1, X_2)
$$

---

### 6. 小结

极限 $H(S) = H(X_3 \mid X_1, X_2)$ 的核心在于：
1. **链式规则展开**：将联合熵分解为条件熵之和。
2. **二阶马尔可夫性质**：使得条件熵仅依赖于最近两个状态，简化为 $H(X_i \mid X_{i-1}, X_{i-2})$。
3. **定常性**：保证所有 $H(X_i \mid X_{i-1}, X_{i-2})$ 相等，从而条件熵的平均值等于单个条件熵。

这使得在 $n \to \infty$ 的极限下，早期项对熵速率的贡献被忽略。