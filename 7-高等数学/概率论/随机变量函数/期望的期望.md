---
tags:
  - 数学
dlink:
  - "[[---随机变量函数---]]"
---
计算 $E[E[X]]$ 时，首先需要理解两个概念：条件期望和全概率期望。设 $X$ 是一个随机变量，$E[X]$ 是 $X$ 的期望。

### 1. 条件期望
假设 $X$ 和 $Y$ 是两个随机变量，$E[X|Y]$ 表示在 $Y$ 已知的情况下 $X$ 的条件期望。

### 2. 全概率期望
全概率期望的定理指出：
$$ E[X] = E[E[X|Y]] $$

这意味着在计算 $X$ 的期望时，我们可以先计算 $X$ 在 $Y$ 确定情况下的条件期望，然后对 $Y$ 取期望。

### 证明
利用全概率期望定理，可以得到 $E[E[X]]$ 的计算公式。实际上，对于任意随机变量 $X$ 和 $Y$，有：
$$ E[E[X|Y]] = E[X] $$

因此，假设 $Y$ 是确定的常数，则有 $E[X|Y] = E[X]$。进一步地，取全概率期望，可以得到：
$$ E[E[X|Y]] = E[X] $$

由于 $Y$ 是确定的常数，所以：
$$ E[E[X]] = E[X] $$

### 总结
$E[E[X]] = E[X]$ 确实成立，这来源于全概率期望的性质。简言之，$E[E[X]]$ 等于 $X$ 的期望 $E[X]$。



---


### 1. 证明 $E[E[X]] = E[X]$

假设我们有一个随机变量 $X$ 和另一个随机变量 $Y$。根据全概率公式，我们有：

$$ E[X] = E[E[X|Y]] $$

这个公式表明，我们可以先对 $X$ 在 $Y$ 已知条件下求期望，然后再对 $Y$ 求期望，结果是一样的。

为了更直观地理解这一点，可以考虑 $X$ 和 $Y$ 是离散随机变量的情况：

$$ E[X] = \sum_y P(Y=y) E[X|Y=y] $$

这意味着，我们先计算每个 $Y=y$ 的条件下 $X$ 的期望 $E[X|Y=y]$，然后用 $P(Y=y)$ 加权求和。

### 2. 证明 $E[E[X]^2] \neq E[X \cdot E[X]]$

#### 首先，我们需要明确两个表达式的意义：

1. $E[E[X]^2]$ 表示期望的平方的期望值。
2. $E[X \cdot E[X]]$ 表示期望乘以期望的期望值。

假设 $E[X]$ 是一个常数，我们可以计算 $E[X \cdot E[X]]$。由于 $E[X]$ 是常数，所以它可以从期望算子中移出：

$$ E[X \cdot E[X]] = E[X] \cdot E[E[X]] $$

根据上面的证明，$E[E[X]] = E[X]$，所以：

$$ E[X \cdot E[X]] = E[X] \cdot E[X] = (E[X])^2 $$

#### 然而，$E[E[X]^2]$ 的含义不同

$$ E[E[X]^2] = E[(E[X])^2] $$

假设 $X$ 的期望是 $\mu = E[X]$，那么：

$$ E[E[X]^2] = E[\mu^2] = \mu^2 $$

从这个推导可以看出：

$$ E[E[X]^2] = \mu^2 = (E[X])^2 $$

这表明 $E[E[X]^2]$ 与 $E[X \cdot E[X]]$ 都等于 $(E[X])^2$。

### 总结
在上述推导中，我们可以看到 $E[E[X]] = E[X]$ 的结论来源于全概率公式。而 $E[E[X]^2] = E[X \cdot E[X]]$ 在期望值 $\mu$ 为常数时，二者结果相等。

为了更好地理解和证明这些期望的性质，关键在于明确条件期望和全概率公式的应用。通过逐步计算和代入，可以得到更直观的结果。